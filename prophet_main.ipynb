{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import os\n",
    "import csv\n",
    "\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from scipy.fft import fft\n",
    "from prophet import Prophet\n",
    "from prophet.serialize import model_to_json\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, r2_score, \\\n",
    "    explained_variance_score, accuracy_score, precision_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "def get_delimiter(file_path, bytes=4096):\n",
    "    \"\"\"\n",
    "    Retrieves the delimiter of a csv file.\n",
    "    Args:\n",
    "        file_path: path to csv file to read\n",
    "        bytes: n bytes to read to detect the delimiter (higher is more guaranteed accuracy)\n",
    "\n",
    "    Returns:\n",
    "        delimiter: delimiter of the csv file located in the given path\n",
    "\n",
    "    \"\"\"\n",
    "    sniffer = csv.Sniffer()\n",
    "    data = open(file_path, \"r\").read(bytes)\n",
    "    delimiter = sniffer.sniff(data).delimiter\n",
    "    return delimiter"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "def read_csvs_from_folder(folder_path, bytes=4096, list=False):\n",
    "    \"\"\"\n",
    "    Reads all CSV files in a folder and stores them as pandas DataFrames in a list.\n",
    "    Automatically detects the delimiter for each CSV file.\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): Path to the folder containing CSV files.\n",
    "        bytes (int): Number of bytes to read from each file for delimiter detection.\n",
    "\n",
    "    Returns:\n",
    "        Concatenated pandas DataFrame containing each CSV file in the folder.\n",
    "    \"\"\"\n",
    "    # Get a list of all CSV files in the folder\n",
    "    csv_files = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if file.endswith('.csv')]\n",
    "\n",
    "    # Read each CSV file into a pandas DataFrame and store them in a list\n",
    "    dataframes = []\n",
    "    for file in csv_files:\n",
    "        delimiter = get_delimiter(file, bytes)\n",
    "        df = pd.read_csv(file, delimiter=delimiter)\n",
    "        dataframes.append(df)\n",
    "\n",
    "    if not list:\n",
    "        dataframes = pd.concat(dataframes, axis=0, ignore_index=True)\n",
    "    return dataframes\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "def query_yf(stock: tuple, period: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Query the Yahoo Finance API for a given stock and store the data.\n",
    "\n",
    "    :param stock: tuple\n",
    "        A tuple containing three elements:\n",
    "        - company (str): The name of the company.\n",
    "        - ticker (str): The stock ticker symbol of the company.\n",
    "        - exchange (str): The stock exchange where the company is listed.\n",
    "    :param period: int\n",
    "        The number of days of data to retrieve.\n",
    "\n",
    "    :return: data: a pandas dataframe of the data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Extract company, ticker, and exchange from the stock tuple\n",
    "        company, ticker, exchange = stock\n",
    "\n",
    "        yesterday = datetime.now() - timedelta(days=period)\n",
    "        today = datetime.now()\n",
    "\n",
    "        yesterday_str = yesterday.strftime('%Y-%m-%d')\n",
    "        today_str = today.strftime('%Y-%m-%d')\n",
    "\n",
    "        # Query the API using yfinance\n",
    "        stock_data = yf.Ticker(ticker)\n",
    "        data = stock_data.history(period='1d', start=yesterday_str, end=today_str)\n",
    "\n",
    "        # Add the company name to the dataframe\n",
    "        data['Company'] = company\n",
    "        data['Ticker'] = ticker\n",
    "        data['Exchange'] = exchange\n",
    "\n",
    "        # Reorder the columns\n",
    "        data = data[['Company', 'Ticker', 'Exchange', 'Open', 'High', 'Low', 'Close', 'Volume']]\n",
    "\n",
    "        # Convert DataFrame index to a 'DatetimeIndex' without time zone information\n",
    "        data.index = data.index.tz_localize(None)  # this is necessary for some algorithms\n",
    "\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving data: {e}\")\n",
    "        return None"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "def query_yf_list(stocks: pd.DataFrame, period: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Query the Yahoo Finance API for all stocks in a list based on their exchange.\n",
    "\n",
    "    :param stocks: list\n",
    "        A list of tuples containing three elements:\n",
    "        - company (str): The name of the company.\n",
    "        - ticker (str): The stock ticker symbol of the company.\n",
    "        - exchange (str): The stock exchange where the company is listed.\n",
    "    :param period: int\n",
    "        The number of days of data to retrieve.\n",
    "\n",
    "    :return: data: a list of pandas dataframes of the data\n",
    "    \"\"\"\n",
    "    # Create an empty list\n",
    "    data = []\n",
    "\n",
    "    # Loop through the list of stocks\n",
    "    for _, row in stocks.iterrows():\n",
    "        stock = (row['Company'], row['Ticker'], row['Stock Exchange'])\n",
    "\n",
    "        # Query the API using yfinance\n",
    "        stock_data = query_yf(stock, period)\n",
    "\n",
    "        # Append the data to the dataframe\n",
    "        if stock_data is not None:\n",
    "            data.append(stock_data)\n",
    "\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "def save_stocks_to_csv(data_list: [pd.DataFrame], folder_path: str = \"stock_data\"):\n",
    "    \"\"\"\n",
    "    Save a list of stock dataframes to a folder, each as a separate CSV file {company_name} data.csv.\n",
    "    :param data_list: list of dataframes to save\n",
    "    :param folder_path: folder path to save csvs to\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "        for df in data_list:\n",
    "            df.reset_index(inplace=True)\n",
    "            company = df.iloc[0]['Company']\n",
    "            df.to_csv(os.path.join(folder_path, f\"{company} data.csv\"), index=None)\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving data: {e}\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data Processing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "def day_average_std(df: pd.DataFrame, columns: [str] = ['Close', 'Open', 'High', 'Low', 'Volume'], days: int = 30, company_name: str = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute the n-day average and standard deviation of the stock price.\n",
    "    :param column: column to average\n",
    "    :param df: dataframe of stock data\n",
    "    :param days: number of days to average\n",
    "    :return: dataframe of stock data with added column for an n day average\n",
    "    \"\"\"\n",
    "    for column in columns:\n",
    "        if company_name is not None:\n",
    "            column_title = f\"{company_name}-{column} Day Avg\"\n",
    "        else:\n",
    "            column_title = f\"{column} Day Avg\"\n",
    "\n",
    "        df[column_title] = df[column].rolling(days).mean().shift(1).astype('float32')  # shift to not include today\n",
    "        day_mean = df[column].iloc[0:days+1].mean().astype('float32')\n",
    "        df[column_title] = df[column_title].fillna(day_mean)\n",
    "\n",
    "        # now add the standard deviation\n",
    "        if company_name is not None:\n",
    "            column_title = f\"{company_name}-{column} Day Std\"\n",
    "        else:\n",
    "            column_title = f\"{column} Day Std\"\n",
    "        df[column_title] = df[column].rolling(days).std().shift(1).astype('float32')  # shift to not include today\n",
    "        day_std = df[column].iloc[0:days+1].std()\n",
    "        df[column_title] = df[column_title].fillna(day_std)\n",
    "\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "def overall_averages(data_list: [pd.DataFrame]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute the average values for each column for all stocks in the list,\n",
    "    corresponding to the previous day's averages.\n",
    "    :param data_list: list of dataframes of individual stock data.\n",
    "    :return: dataframe of overall averages.\n",
    "    \"\"\"\n",
    "    concatenated_df = pd.concat(data_list)\n",
    "    concatenated_df.drop(columns=['Company', 'Ticker', 'Exchange'], inplace=True)\n",
    "    concatenated_df.set_index('Date', inplace=True)\n",
    "\n",
    "    # Calculate daily averages\n",
    "    daily_averages = concatenated_df.groupby(concatenated_df.index).mean().astype('float32')\n",
    "\n",
    "    # Shift the averages to represent the previous day\n",
    "    daily_averages = daily_averages.shift(1).astype('float32')\n",
    "\n",
    "    # Rename columns to reflect they are lagged values\n",
    "    daily_averages.columns = ['All Prev Day Avg ' + col for col in daily_averages.columns]\n",
    "    if 'index' in daily_averages.columns:\n",
    "        daily_averages.drop(columns=['All Prev Day Avg index'], inplace=True)\n",
    "\n",
    "    return daily_averages\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "def exchange_averages(data_list: [pd.DataFrame]) -> [pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Compute the average values for each column for all stocks in the exchange,\n",
    "    corresponding to the previous day's averages.\n",
    "    :param data_list: list of dataframes of individual stock data.\n",
    "    :return: dictionary of dataframes of exchange averages.\n",
    "    \"\"\"\n",
    "    concatenated_df = pd.concat(data_list)\n",
    "\n",
    "    # Group by 'Date' and 'Exchange'\n",
    "    grouped = concatenated_df.groupby(['Date', 'Exchange'])\n",
    "\n",
    "    # Calculate the average of the required columns\n",
    "    averages = grouped[['Open', 'High', 'Low', 'Close', 'Volume']].mean().astype('float32')\n",
    "\n",
    "    # Shift the averages to represent the previous day\n",
    "    averages = averages.groupby(level='Exchange').shift(1).astype('float32')\n",
    "\n",
    "    # Rename columns to reflect they are lagged values\n",
    "    averages.columns = ['Exchange Prev Day Avg ' + col for col in averages.columns]\n",
    "\n",
    "    # Create a dictionary of dataframes for each exchange\n",
    "    exchange_dfs = {exchange: df.reset_index() for exchange, df in averages.groupby(level='Exchange')}\n",
    "\n",
    "    return exchange_dfs\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "def add_exchange_averages_to_stocks(data_list: [pd.DataFrame], exchange_dfs: dict) -> [pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Add exchange averages to each stock in the data list.\n",
    "\n",
    "    :param data_list: list of dataframes of individual stock data.\n",
    "    :param exchange_dfs: dictionary of dataframes containing exchange averages.\n",
    "    :return: list of dataframes with added exchange average columns.\n",
    "    \"\"\"\n",
    "    updated_data_list = []\n",
    "\n",
    "    for stock_df in data_list:\n",
    "        exchange_name = stock_df['Exchange'].iloc[0]\n",
    "\n",
    "        # Get the corresponding exchange average dataframe\n",
    "        exchange_avg_df = exchange_dfs.get(exchange_name, None)\n",
    "\n",
    "        updated_df = pd.merge(stock_df, exchange_avg_df, how='left', on=['Date', 'Exchange'])\n",
    "        updated_data_list.append(updated_df)\n",
    "\n",
    "    return updated_data_list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "def add_overall_averages_to_stocks(data_list: [pd.DataFrame], average_dfs: [pd.DataFrame]):\n",
    "    \"\"\"\n",
    "    Add overall averages to each stock in the data list.\n",
    "\n",
    "    :param data_list: list of dataframes of individual stock data.\n",
    "    :param average_dfs: list of dataframes containing overall averages.\n",
    "    :return: list of dataframes with added overall average columns.\n",
    "    \"\"\"\n",
    "    updated_data_list = []\n",
    "\n",
    "    for stock_df in data_list:\n",
    "        updated_df = pd.merge(stock_df, average_dfs, how='left', on='Date')\n",
    "        updated_data_list.append(updated_df)\n",
    "\n",
    "    return updated_data_list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "def detect_seasonality(df: pd.DataFrame, max_period: int = 365) -> (int, int, int):\n",
    "    \"\"\"\n",
    "    Detect the seasonalities in a time series using the Fourier transform.\n",
    "    :param df: Dataframe of stock data\n",
    "    :param max_period: the max period to consider for seasonalities\n",
    "    :return: the top three seasonalities for the 'Close' column\n",
    "    \"\"\"\n",
    "\n",
    "    num_seasonalities = 3\n",
    "    tolerance = 0.05\n",
    "\n",
    "    # Perform the Fourier transform on the 'Close' column\n",
    "    close_array = df['Close'].to_numpy()\n",
    "    close_fft = fft(close_array)\n",
    "    frequencies = np.fft.fftfreq(len(close_fft), d=1)  # d is the spacing between samples, which is 1 trading day\n",
    "    power_spectrum = np.abs(close_fft) ** 2\n",
    "\n",
    "    # Exclude the zero frequency term for analysis\n",
    "    positive_frequencies = frequencies[frequencies > 0]\n",
    "    positive_power_spectrum = power_spectrum[frequencies > 0]\n",
    "\n",
    "    # Find all peaks in the frequency spectrum sorted by power\n",
    "    peaks_indices = np.argsort(positive_power_spectrum)[::-1]  # Sort in descending order of power\n",
    "    peak_frequencies = positive_frequencies[peaks_indices]\n",
    "    peaks_periods = 1 / peak_frequencies\n",
    "\n",
    "    # Filter to find peaks corresponding to periods under the specified max_period\n",
    "    filtered_peaks_periods = peaks_periods[peaks_periods < max_period]\n",
    "\n",
    "    # Select the top three seasonalities, excluding harmonics\n",
    "    likely_seasonalities = []\n",
    "    for period in filtered_peaks_periods:\n",
    "        if not any(abs(period - p) < tolerance for p in likely_seasonalities):\n",
    "            likely_seasonalities.append(period)\n",
    "        if len(likely_seasonalities) == num_seasonalities:\n",
    "            break\n",
    "\n",
    "    # Return the likley seasonalities rounded to integers\n",
    "    return np.round(likely_seasonalities).astype(int)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "def calculate_standard_metrics(truth_series: pd.Series, predicted_series: pd.Series) -> (float, float, float, float, float, float):\n",
    "    \"\"\"\n",
    "    Calculate standard metrics for evaluating a trading strategy.\n",
    "    :param truth_series: series of actual prices\n",
    "    :param predicted_series: series of predicted prices\n",
    "    :return: RMSE, MAE, MAPE, Rsq, Explained Variance\n",
    "    \"\"\"\n",
    "    rmse = mean_squared_error(truth_series, predicted_series, squared=False)\n",
    "    mae = mean_absolute_error(truth_series, predicted_series)\n",
    "    mape = mean_absolute_percentage_error(truth_series, predicted_series)\n",
    "    rsq = r2_score(truth_series, predicted_series)\n",
    "    ev = explained_variance_score(truth_series, predicted_series)\n",
    "    return rmse, mae, mape, rsq, ev"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "def direction_evaluation(df: pd.DataFrame, truth_column: str, predicted_column: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Add a column to the dataframe indicating whether the predicted direction (up or down) matches the actual subsequent movement\n",
    "    from the previous day's price to today's price.\n",
    "\n",
    "    :param df: dataframe of data with actual and predicted price columns\n",
    "    :param truth_column: string for the title of the truth column (actual price)\n",
    "    :param predicted_column: string for the title of the predicted price column\n",
    "    :return: dataframe with an additional column indicating if the predicted direction is correct\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    # Determine the actual direction by comparing today's actual price to yesterday's actual price\n",
    "    df['Actual Direction'] = np.where(df[truth_column] > df[truth_column].shift(1), 'Up', 'Down')\n",
    "    # Determine the predicted direction by comparing today's predicted price to yesterday's actual price\n",
    "    df['Predicted Direction'] = np.where(df[predicted_column] > df[truth_column].shift(1), 'Up', 'Down')\n",
    "    # Compare the actual direction to the predicted direction\n",
    "    df['Direction Correct'] = np.where(df['Actual Direction'] == df['Predicted Direction'], 'Correct', 'Incorrect')\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "def calculate_accuracy(df: pd.DataFrame, truth_column: str = 'Close', predicted_column: str = 'Predicted Close') -> (float, float):\n",
    "    \"\"\"\n",
    "    Calculate the accuracy of a trading strategy by comparing the predicted direction to the actual direction.\n",
    "    :param df: dataframe of data with actual and predicted price columns\n",
    "    :param truth_column: column containing the actual price\n",
    "    :param predicted_column: column containing the predicted price\n",
    "    :return: accuracy, precision\n",
    "    \"\"\"\n",
    "    df = direction_evaluation(df, truth_column, predicted_column)\n",
    "    accuracy = accuracy_score(df['Actual Direction'], df['Predicted Direction'])\n",
    "    precision = precision_score(df['Actual Direction'], df['Predicted Direction'], pos_label='Up')\n",
    "    return accuracy, precision"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "def simulate_trading(df: pd.DataFrame, initial_funds: int = 10000, truth_column: str = 'Close', predicted_column: str = 'Predicted Close') -> (float, float):\n",
    "    \"\"\"\n",
    "    Simulate trading based on predictions to calculate profitability and average profit per trade.\n",
    "\n",
    "    :param df: dataframe of data with actual and predicted price columns\n",
    "    :param initial_funds: initial investment amount\n",
    "    :param truth_column: string for the title of the truth column (actual price)\n",
    "    :param predicted_column: string for the title of the predicted price column\n",
    "    :return: net gain or loss from trading strategy, average profit per trade\n",
    "    \"\"\"\n",
    "    funds = initial_funds\n",
    "    shares = 0\n",
    "    trades = []\n",
    "\n",
    "    df = df.copy()\n",
    "    df['Predicted Tomorrow'] = df[predicted_column].shift(-1)  # shift predictions to align with the day they are for\n",
    "\n",
    "    for i in range(len(df) - 1):  # minus 1 because the last day's prediction is for a day outside of our dataframe\n",
    "        today_price = df[truth_column].iloc[i]\n",
    "        predicted_tomorrow_price = df['Predicted Tomorrow'].iloc[i]\n",
    "\n",
    "        if not np.isnan(predicted_tomorrow_price) or not np.isnan(today_price):\n",
    "            # If the predicted price for tomorrow is higher than today's price, buy\n",
    "            if predicted_tomorrow_price > today_price:\n",
    "                shares_bought = funds // today_price\n",
    "                funds -= shares_bought * today_price\n",
    "                shares += shares_bought\n",
    "\n",
    "            # The next day, sell all shares if any were bought\n",
    "            if shares > 0:\n",
    "                next_day_price = df[truth_column].iloc[i + 1]\n",
    "                trade_profit = shares * (next_day_price - today_price)  # calculate profit for this trade\n",
    "                funds += shares * next_day_price\n",
    "                shares = 0  # reset shares to 0 after selling\n",
    "                trades.append(trade_profit)  # keep track of the profit from this trade\n",
    "\n",
    "    net_gain = funds - initial_funds\n",
    "    if shares != 0:\n",
    "        funds += shares * df[truth_column].iloc[-1]\n",
    "    if not trades:\n",
    "        average_profit = 0\n",
    "    else:\n",
    "        average_profit = sum(trades) / len(trades)\n",
    "    net_gain_percent = net_gain / initial_funds * 100\n",
    "\n",
    "    return net_gain, average_profit, net_gain_percent"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Comparison to S&P 500 Uranium ETF"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "def compare_to_ETF(urnm: pd.DataFrame, df: pd.DataFrame = None, window: int = 100, initial_funds: int = 10000):\n",
    "    \"\"\"\n",
    "    Compare the profitability of a trading strategy to the profitability of investing in the S&P 500 URNM ETF.\n",
    "    :param urnm: dataframe of URNM data\n",
    "    :param df: dataframe of data with actual and predicted price columns for a stock\n",
    "    :param truth_column: column containing the actual price\n",
    "    :param predicted_column: column containing the predicted price\n",
    "    :return: metrics of using the ETF as a trading strategy\n",
    "\n",
    "    Note this can be done in two ways:\n",
    "        1. Investing into the ETF and holding.\n",
    "        2. Using the ETF as a trading strategy.\n",
    "    This function will do both using the historical data of the ETF.\n",
    "    \"\"\"\n",
    "    urnm_copy = urnm.copy()\n",
    "    if df is not None:\n",
    "        start_date = df['Date'].iloc[0]\n",
    "        end_date = df['Date'].iloc[-1]\n",
    "        urnm = urnm[(urnm['Date'] >= start_date) & (urnm['Date'] <= end_date)]\n",
    "    else:\n",
    "        start_date = urnm['Date'].iloc[-window]\n",
    "        end_date = urnm['Date'].iloc[-1]\n",
    "\n",
    "    # option one, invest and Hold\n",
    "    start_price = urnm['Close'].iloc[0]\n",
    "    shares = initial_funds // start_price\n",
    "\n",
    "    end_price = urnm['Close'].iloc[-1]\n",
    "    funds = shares * end_price\n",
    "\n",
    "    hold_net_gain = funds - initial_funds\n",
    "    net_gain_percent = hold_net_gain / initial_funds * 100\n",
    "\n",
    "    return hold_net_gain, net_gain_percent\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Running Prophet"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Start Here to Run Prophet\n",
    "Run all of the above cells.\n",
    "Then follow the comments for the Load or Query data section.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load or Query Data:\n",
    "To load or query data, you will need to upload either the given stock list file or the stock_data folder."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# run this cell for querying using the stock list file\n",
    "stocks_list = pd.read_csv('../Uranium Company Master List.csv')\n",
    "periods = 365*5 # 3 years, however, some stocks only have 2022 to the present (was 5 years, need to conserve memory on my machine)\n",
    "data_list = query_yf_list(stocks_list, periods)\n",
    "for data in data_list:\n",
    "    data.reset_index(inplace=True)  # must have an integer index for Prophet"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note: Output from the above cell may contain warnings about missing data. This is expected as the listings of companies change."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# run this cell for loading data from a folder mounted to your environment (optional)\n",
    "data_folder = 'stock_data'\n",
    "data_list = read_csvs_from_folder(data_folder, list=True)\n",
    "urnm_data_folder = 'stock_data/SP Uranium ETF'\n",
    "urnm_data = read_csvs_from_folder(urnm_data_folder, list=False)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# run this to query data for the SP 500 Uranium ETF\n",
    "stock = \"Sprott Uranium Miners ETF\", \"URNM\", \"XNYS\"\n",
    "period = 365*5\n",
    "urnm_data = query_yf(stock, period)\n",
    "urnm_data.reset_index(inplace=True)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# run this cell to save the data to a folder (optional)\n",
    "save_stocks_to_csv(data_list, folder_path='stock_data')\n",
    "urnm_data.to_csv(os.path.join(\"stock_data/SP Uranium ETF\", \"Sprott Uranium Miners ETF data.csv\"), index='Date')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Preprocessing and Running Prophet"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def run_prophet(df: pd.DataFrame, custom_season: int = None, include_exchange_avgs = False, include_overall_avgs = False, save_model = False) -> [dict]:\n",
    "    \"\"\"\n",
    "    Runs the Prophet model on a given DataFrame to predict future stock prices.\n",
    "\n",
    "    This function preprocesses the input DataFrame, splits it into training and testing datasets,\n",
    "    builds and fits a Prophet model with optional custom seasonality, and evaluates the model's predictions.\n",
    "    It returns a dictionary containing various performance metrics.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The input DataFrame containing stock market data. It must include the columns:\n",
    "      'Date', 'Company', 'Ticker', 'Exchange', 'Open', 'High', 'Low', 'Close', and 'Volume'.\n",
    "    - custom_season (int, optional): The number of days for the custom seasonality period.\n",
    "      If None, no custom seasonality is added. Default is None.\n",
    "\n",
    "    Returns:\n",
    "    - dict: A dictionary containing the following keys and their corresponding values:\n",
    "      - 'RMSE' (float): Root Mean Squared Error of the model's predictions.\n",
    "      - 'MAE' (float): Mean Absolute Error of the model's predictions.\n",
    "      - 'MAPE' (float): Mean Absolute Percentage Error of the model's predictions.\n",
    "      - 'RSQ' (float): R-squared value indicating the goodness of fit.\n",
    "      - 'Accuracy' (float): Accuracy of the model's directional predictions.\n",
    "      - 'Precision' (float): Precision of the model's directional predictions.\n",
    "      - 'Net Gain' (float): Net gain from simulated trading based on model predictions.\n",
    "      - 'Avg Profit' (float): Average profit per trade from simulated trading.\n",
    "      - 'Net Gain Percent' (float): Net gain percentage from simulated trading.\n",
    "\n",
    "    The function internally uses the Prophet model for time series forecasting and several custom functions\n",
    "    for preprocessing and evaluation:\n",
    "    - `day_average_std` for adding day average feature,\n",
    "    - `calculate_standard_metrics` for basic evaluation metrics,\n",
    "    - `direction_evaluation` for evaluating the direction of change,\n",
    "    - `calculate_accuracy` for accuracy and precision calculation,\n",
    "    - `simulate_trading` for simulating trading based on model predictions.\n",
    "\n",
    "    Example:\n",
    "    ```python\n",
    "    import pandas as pd\n",
    "    df = pd.read_csv('stock_data.csv')\n",
    "    results = run_prophet(df)\n",
    "    print(results)\n",
    "    ```\n",
    "\n",
    "    Note:\n",
    "    The function assumes that 'Close' column in the input DataFrame is the target variable for prediction,\n",
    "    and the next day's closing price is predicted. The function also modifies the input DataFrame by adding\n",
    "    new columns and dropping unnecessary ones. Ensure that the DataFrame is in the correct format before calling this function.\n",
    "    \"\"\"\n",
    "\n",
    "    # preprocessing\n",
    "    df = df.copy()\n",
    "    company = df['Company'].iloc[0]\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df['y'] = df['Close'].shift(-1)\n",
    "    df['ds'] = df['Date']\n",
    "    df = day_average_std(df)\n",
    "    df = df.drop(columns=['Date', 'Company', 'Ticker', 'Exchange', 'Close'], inplace=False)\n",
    "\n",
    "    split = round(len(df) * 0.8)\n",
    "\n",
    "    train_df = df.iloc[:split-100]\n",
    "    test_df = df.iloc[split-100:]\n",
    "\n",
    "    # model\n",
    "    model = Prophet(daily_seasonality=True, weekly_seasonality=False, yearly_seasonality=False)\n",
    "    regressors = ['Open', 'High', 'Low', 'Volume', ] # , 'Exchange Close', 'Exchange Volume']\n",
    "    if include_exchange_avgs is True:\n",
    "        regressors += ['Exchange Prev Day Avg Open', 'Exchange Prev Day Avg High', 'Exchange Prev Day Avg Low', 'Exchange Prev Day Avg Close', 'Exchange Prev Day Avg Volume']\n",
    "    if include_overall_avgs is True:\n",
    "        regressors += ['All Prev Day Avg Open', 'All Prev Day Avg High', 'All Prev Day Avg Low', 'All Prev Day Avg Close', 'All Prev Day Avg Volume']\n",
    "    for regressor in regressors:\n",
    "        regressors.append(f'{regressor} Day Avg')\n",
    "        regressors.append(f'{regressor} Day Std')\n",
    "    regressors += ['Close Day Avg', 'Close Day Std']\n",
    "    for regressor in regressors:\n",
    "        model.add_regressor(regressor)\n",
    "\n",
    "    if custom_season is not None:\n",
    "        model.add_seasonality(name='custom_season', period=custom_season, fourier_order=5)\n",
    "\n",
    "    model.fit(train_df)\n",
    "\n",
    "    event_horizons = [5, 10, 20, 50, 100]\n",
    "    metrics_dicts = []\n",
    "\n",
    "    for horizon in event_horizons:\n",
    "        if horizon > len(test_df['y'].values):\n",
    "            print(\"Warning: Event horizon is larger than the test set size. Default test set size is 20% of the \" +\n",
    "                  f\"dataset. Current horizon is: {len(test_df['y'].values)}.\")\n",
    "        else:\n",
    "            test_horizon_df = test_df.iloc[:horizon]\n",
    "\n",
    "        future = test_horizon_df.drop('y', axis=1)\n",
    "\n",
    "        forecast = model.predict(future)\n",
    "        test_horizon_df['Predicted Close'] = forecast['yhat'].values\n",
    "\n",
    "        # evaluation\n",
    "        true_series = test_horizon_df['y'].iloc[:-1]\n",
    "        pred_series = test_horizon_df['Predicted Close'].shift(1).iloc[1:]\n",
    "\n",
    "        metrics_dict = {}\n",
    "        rmse, mae, mape, rsq, ev = calculate_standard_metrics(true_series, pred_series)\n",
    "        metrics_dict['RMSE'] = rmse\n",
    "        metrics_dict['MAE'] = mae\n",
    "        metrics_dict['MAPE'] = mape\n",
    "        metrics_dict['RSQ'] = rsq\n",
    "\n",
    "        direction_df = direction_evaluation(test_horizon_df, 'y', 'Predicted Close')\n",
    "        accuracy, precision = calculate_accuracy(direction_df, 'y', 'Predicted Close')\n",
    "        metrics_dict['Accuracy'] = accuracy\n",
    "        metrics_dict['Precision'] = precision\n",
    "\n",
    "        net_gain, avg_profit, net_gain_percent = simulate_trading(direction_df, 10000, 'y', 'Predicted Close')\n",
    "        metrics_dict['Net Gain'] = net_gain\n",
    "        metrics_dict['Avg Profit'] = avg_profit\n",
    "        metrics_dict['Net Gain Percent'] = net_gain_percent\n",
    "\n",
    "        metrics_dicts.append(metrics_dict)\n",
    "\n",
    "    if save_model:\n",
    "        # save model fitted to latest data for future predictions\n",
    "        model.fit(df)\n",
    "\n",
    "        model_path = 'prophet_models'\n",
    "        if not os.path.exists(model_path):\n",
    "            os.makedirs(model_path)\n",
    "        model_path = os.path.join(model_path, f\"{company}_model.json\")\n",
    "\n",
    "        with open(model_path, 'w') as f:\n",
    "            f.write(model_to_json(model))\n",
    "\n",
    "    return metrics_dicts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "exchange_averages_dfs = exchange_averages(data_list)\n",
    "overall_averages_dfs = overall_averages(data_list)\n",
    "data_list = add_exchange_averages_to_stocks(data_list, exchange_averages_dfs)\n",
    "data_list = add_overall_averages_to_stocks(data_list, overall_averages_dfs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# have a list to hold all of the horizon list dataframes\n",
    "stocks_horizon_metrics = []\n",
    "\n",
    "for data in data_list:\n",
    "    seasonalities = detect_seasonality(data)\n",
    "    metrics_list = run_prophet(df=data, custom_season=seasonalities[0], include_exchange_avgs=False, include_overall_avgs=False, save_model=True)\n",
    "    event_horizons = [5, 10, 20, 50, 100]\n",
    "    horizons_metrics_list = []\n",
    "\n",
    "    for i in range(len(event_horizons)):\n",
    "        row = {\n",
    "            'Company': data['Company'][0],\n",
    "            'Ticker': data['Ticker'][0],\n",
    "            'Exchange': data['Exchange'][0],\n",
    "            'Event Horizon': event_horizons[i],\n",
    "            'RMSE': metrics_list[i]['RMSE'],\n",
    "            'MAE': metrics_list[i]['MAE'],\n",
    "            'MAPE': metrics_list[i]['MAPE'],\n",
    "            'R2': metrics_list[i]['RSQ'],\n",
    "            'Accuracy': metrics_list[i]['Accuracy'],\n",
    "            'Precision': metrics_list[i]['Precision'],\n",
    "            'Net Gain': metrics_list[i]['Net Gain'],\n",
    "            'Net Gain %': metrics_list[i]['Net Gain Percent'],\n",
    "            'Avg Profit': metrics_list[i]['Avg Profit']\n",
    "        }\n",
    "        horizons_metrics_list.append(row)\n",
    "    company_df = pd.DataFrame(horizons_metrics_list)\n",
    "    stocks_horizon_metrics.append(company_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Examining Results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# average metrics for each horizon\n",
    "overall_horizon_metrics = []\n",
    "for df in stocks_horizon_metrics:\n",
    "    df = df.copy()\n",
    "    df.drop(['Company', 'Ticker', 'Exchange'], axis=1, inplace=True)\n",
    "    overall_horizon_metrics.append(df)\n",
    "overall_horizon_metrics = pd.concat(overall_horizon_metrics)\n",
    "overall_horizon_metrics = overall_horizon_metrics.groupby('Event Horizon').mean()\n",
    "overall_horizon_metrics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ETF is being traded in more of a long term fashion\n",
    "etf_net_gain, etf_net_gain_percent = compare_to_ETF(urnm_data, initial_funds=10000)\n",
    "print(\"ETF Net Gain: \", etf_net_gain)\n",
    "print(\"ETF Net Gain %: \", etf_net_gain_percent)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize an empty DataFrame to hold Net Gain % for all companies\n",
    "consolidated_gains = pd.DataFrame()\n",
    "\n",
    "for metric_df in stocks_horizon_metrics:\n",
    "    company_name = metric_df['Company'][0]\n",
    "    # Extracting Net Gain % for the company\n",
    "    net_gain_percent = metric_df['Net Gain %'].iloc[4]  # 100 day Event Horizon\n",
    "\n",
    "    # Append the Net Gain % to the consolidated DataFrame\n",
    "    consolidated_gains = consolidated_gains.append({\n",
    "        'Company': company_name,\n",
    "        'Net Gain %': net_gain_percent\n",
    "    }, ignore_index=True)\n",
    "\n",
    "# Now that we have all the data consolidated, let's plot it\n",
    "consolidated_gains.plot.bar(x='Company', y='Net Gain %', title=\"Companies Net Gain %\")\n",
    "plt.show()  # Display the plot\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
